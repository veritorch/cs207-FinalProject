{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>CS 207 Final Project: Milestone 2</center>\n",
    "<center>November 2019</center>\n",
    "\n",
    "## Introduction\n",
    "\n",
    "\n",
    "Efficiently and accurately evaluating derivatives of functions is one of the most important operations in science and engineering. Automatic differentiation (AD) is a technique which, given a function $f$ and a point, automatically evaluates that point's derivative. AD is less costly than symbolic defferentiation, while achieving machine precision compared with finite differentiation. This library implements the forward mode of AD, along with some additional features.\n",
    "\n",
    "\n",
    "## Background\n",
    "\n",
    "We present below some of the key concepts and formulae upon which we build the veritorch library:\n",
    "\n",
    "### Chain rule\n",
    "\n",
    "Chain rule is fundamental to AD when we decompose functions.\n",
    "\n",
    "Suppose we have $h(u(t), v(t))$, its derivative with respect to $t$ is:\n",
    "\n",
    "$$\\frac{\\partial h}{\\partial t} = \\frac{\\partial h}{\\partial u}\\frac{\\partial u}{\\partial t} + \\frac{\\partial h}{\\partial v}\\frac{\\partial v}{\\partial t}.$$\n",
    "\n",
    "For the general function $h(y_1(\\mathbf{x}), \\dotsc,y_n(\\mathbf{x}))$, where we replace $t$ with a vector $\\mathbf{x} \\in \\mathbb{R}^m$ and $h$ a function of $n$ other functions $y_i$, the derivative is:\n",
    "\n",
    "$$\\nabla_x h = \\sum_{i=1}^n \\frac{\\partial h}{\\partial y_i} \\nabla y_i(\\mathbf{x})$$\n",
    "\n",
    "### Jacobians and vectors\n",
    "\n",
    "If we have a function $\\mathbf{y}(\\mathbf{x})$: $\\mathbb{R}^n \\rightarrow \\mathbb{R}^m$, the Jacobian matrix of it is a matrix representing all the possible partial derivatives combinations as follows:\n",
    "$$\n",
    "\\mathbf{J} = \\begin{bmatrix}\n",
    "\\frac{\\partial \\mathbf{y}}{\\partial x_1} & \\dots  & \\frac{\\partial \\mathbf{y}}{\\partial x_n}\n",
    "\\end{bmatrix} = \\begin{bmatrix} \n",
    "\\frac{\\partial {y_1}}{\\partial x_1} & \\dots & \\frac{\\partial {y_1}}{\\partial x_n} \\\\\n",
    "\\vdots & \\ddots & \\vdots\\\\\n",
    "\\frac{\\partial {y_m}}{\\partial x_1} & \\dots & \\frac{\\partial {y_m}}{\\partial x_n} \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "In general, for example, we have a function $g(\\mathbf{y}(\\mathbf{x}))$. Suppose a vector $\\mathbf{v}$ happens to be the gradient of g with respect the vector $\\mathbf{y}$ as follows: \n",
    "$$\n",
    "\\mathbf{v} = \\begin{bmatrix}\n",
    "\\frac{\\partial g}{\\partial y_1} & \\dots & \\frac{\\partial g}{\\partial y_m}\n",
    "\\end{bmatrix} ^T\n",
    "$$\n",
    "To get the gradient of g with respect to $\\mathbf{x}$, we multiply Jacobian matrix $\\mathbf{J}$ with vector $\\mathbf{v}$: \n",
    "\n",
    "$$\\mathbf{J} \\cdot \\mathbf{v} = \\begin{bmatrix} \n",
    "\\frac{\\partial {y_1}}{\\partial x_1} & \\dots & \\frac{\\partial {y_m}}{\\partial x_n} \\\\\n",
    "\\vdots & \\ddots & \\vdots\\\\\n",
    "\\frac{\\partial {y_1}}{\\partial x_1} & \\dots & \\frac{\\partial {y_m}}{\\partial x_n} \\\\\n",
    "\\end{bmatrix} \n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial g}{\\partial y_1} \\\\\n",
    "\\vdots \\\\ \n",
    "\\frac{\\partial g}{\\partial y_m}\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "\\frac{\\partial g}{\\partial x_1} \\\\\n",
    "\\vdots \\\\ \n",
    "\\frac{\\partial g}{\\partial x_n}\n",
    "\\end{bmatrix} $$\n",
    "\n",
    "### Computational graphs \n",
    "\n",
    "AD exploits the idea that complicated equations could be converted into a sequence of elementary operations which have specified routines for computing derivatives. This process, also called the evaluation trace, can be visualized by a computational graph where each step is an elementary operation. For example, we want to evaluate the derivative of the function: $$f(x) = 5\\exp(x^2)+\\sin(3x)$$\n",
    "Here in this example, the right-most $x_7$ represents the value of $f(x)$, while the left-most $x$ represents our input variable. We construct a computational graph where we take the input $x$ as a node, and we take the constants as nodes as well when applicable. These nodes are connected by lines (edges) to represent the flow of information. \n",
    "\n",
    "![](https://i.imgur.com/uBUpnfc.jpg=300x)\n",
    "\n",
    "\n",
    "\n",
    "### Elementary functions\n",
    "\n",
    "Elementary Functions | Example | Derivative\n",
    ":-:|:-:|:-:\n",
    "exponentials| $e^x$ | $e^x$   \n",
    "logarithms|$log(x)$| $\\frac{1}{x}$ \n",
    "powers| $x^2$| $2x$ \n",
    "trigonometrics| $sin(x)$ | $cos(x)$ \n",
    "inverse trigonometrics|  $arcsin(x)$ | $\\frac{1}{\\sqrt{(1-x^2)}}$ \n",
    "\n",
    "\n",
    "### Dual number\n",
    "$\\forall z_1=x_1+y_1\\epsilon, z_2=x_2+y_2\\epsilon,$ where $x_1, y_1, x_2, y_2\\in \\mathbb{R}$, we have the following properties for dual number:\n",
    "1. $z_1+z_2=(x_1+x_2)+(y_1+y_2)\\epsilon$\n",
    "2. $z_1z_2=(x_1x_2)+(x_1y_2+x_2y_1)\\epsilon$\n",
    "3. $z_1/z_2=(\\frac{x_1}{x_2})+\\frac{x_2y_1-x_1y_2}{x_2^2}$\n",
    "\n",
    "As can be seen from the equations above, there is a close connection between the multiplication/division of dual numbers and the product/quotient rules for derivatives:\n",
    "$$(f(x)g(x))'=f'(x)g(x)+f(x)g'(x)$$\n",
    "$$(\\frac{f(x)}{g(x)})'=\\frac{f'(x)g(x)-f(x)g'(x)}{g^{2}(x)}$$.\n",
    "\n",
    "### Forward mode\n",
    "At the moment, our veritorch package support forward mode only, which uses chain rule to propogate the gradient with respect to the input/independent variables along the computational graph. In the process of gradient propogation, we use the class named Variable that can be updated in a fashion similar to the dual number formula listed above to store the intermediate values and derivatives. In the end, our package will return the jacobian vector product $Jp$. As a result, the forward mode depends on the number of independent parameters involved in the function $f$. If a function actually involves many independent parameters, the forward mode might not be efficient enough and the backward mode should be considered instead. However, due to time constraint, we might not be able to add support of backward mode to our veritorch package.\n",
    "\n",
    "## How to use veritorch\n",
    "\n",
    "To use the veritorch package, users should first run the commands provided below to install our package via pip and import it. We have already uploaded our veritorch package to PyPI.\n",
    "\n",
    "```\n",
    "pip install veritorch\n",
    "python\n",
    ">>>import veritorch.veritorch as vt\n",
    "```\n",
    "\n",
    "After successfully installing and importing the veritorch package, users can take the following steps to evaluate the derivative of $f$ at a point $x$. Here we take $f(x)=f(x_1,x_2,x_3)=x_1x_2x_3,~x=(x_1,x_2,x_3)=(4,5,6)$ as an example:\n",
    "\n",
    "```\n",
    "# First, create an instance of solver class in the veritorch package that\n",
    "# tracks how many of independent variables $f$ takes as input.\n",
    "\n",
    ">>>sol=vt.Solver(3)\n",
    "\n",
    "# Next, use the method create_variable(initial_value) of solver class\n",
    "# to create variable x1, x2, x3 with their values initialized to 4, 5, 6 \n",
    "# (and partial derivatives, with respect to x1, x2, x3 respectively \n",
    "# initialized to 1 by default)\n",
    "\n",
    ">>>x1=sol.create_variable(4)\n",
    ">>>x2=sol.create_variable(5)\n",
    ">>>x3=sol.create_variable(6)\n",
    ">>>f1=x1*x2*x3\n",
    ">>>print(f1)\n",
    "Variable(120, [30,24,20])\n",
    "```\n",
    "\n",
    "\n",
    "The veritorch package will also support composite functions that involve elementary functions, including but not limited to $\\sin(x), \\cos(x), \\exp(x), \\arcsin(x)$:\n",
    "\n",
    "```\n",
    "# create variable x1 with its value initialized to pi \n",
    "# (and derivatives initialized to 1 by default)\n",
    "\n",
    ">>>import math\n",
    ">>>import numpy as np\n",
    ">>>sol=vt.Solver(1)\n",
    ">>>x1=sol.create_variable(math.pi)\n",
    ">>>f1=np.sin(x1)\n",
    ">>>f2=np.cos(f1)\n",
    ">>>f3=np.exp(f2)\n",
    ">>>f4=np.arcsin(f3)\n",
    "\n",
    "# user can also put in a composite function all at once. demo omitted.\n",
    "```\n",
    "\n",
    "We also plan to support the following demo, though it is not supported in this milestone.\n",
    "\n",
    "```\n",
    "# for multi-dimensional function, user can use solver.merge method \n",
    "# to get the jacobian matrix\n",
    "\n",
    ">>>sol=vt.Solver(2)\n",
    ">>>x1=sol.create_variable(1)\n",
    ">>>x2=sol.create_variable(2)\n",
    ">>>f1=x1*x2\n",
    ">>>f2=x1**x2\n",
    ">>>f3=x1+2*x2\n",
    ">>>print(sol.merge(f1, f2, f3))\n",
    "Variable([1,1,5], [[2,1],[2,0],[1,2]])\n",
    "```\n",
    "Then typing \"print(f4)\" will show us the final value and derivative of the composite function.\n",
    "\n",
    "## Software organization\n",
    "\n",
    "### Directory structure\n",
    "\n",
    "We plan to make the final repo follow the directory structure below:\n",
    "```\n",
    "cs207-FinalProject/\n",
    "    README.md\n",
    "    requirements.txt\n",
    "    LICENSE\n",
    "    setup.py\n",
    "    veritorch/\n",
    "        __init__.py\n",
    "        veritorch.py\n",
    "        ...\n",
    "    test/\n",
    "        test.py\n",
    "        ...\n",
    "    docs/\n",
    "        milestone1.ipynb\n",
    "        milestone2.ipynb\n",
    "        ...\n",
    "```\n",
    "\n",
    "### Modules\n",
    "We choose to have only one module published: the veritorch module within our veritorch package. The veritorch module includes a Solver class and a Variable class. The Solver class takes as an input the number of independent variables that the function $f$ has, and tracks how many independent variables we have already created so far. The Variable class takes as input the initial value $x$, and includes methods to overload basic arithmic operators for the veritorch package. While we have a test module, our test module will not be included in the final published package. \n",
    "\n",
    "### Testing\n",
    "All files related to testing will be put in the directory cs207-FinalProject/test/. We will use TravisCI to check whether each pull request can actually build and Codecov to check how many lines of code have been tested. We have activated both of them for this repo and included the badges in the README.md file at the root directory.\n",
    "\n",
    "### Distrubution of the package\n",
    "We will use twine to upload the veritorch package to PyPI (Python Packaging Index) for package distribution. It allows users to search and download packages by keywords or by filters using pip and pipenv. We have already done so and the latest version can be viewed here: https://pypi.org/project/veritorch/0.0.3/\n",
    "\n",
    "## Implementation\n",
    "\n",
    "### Core data structures\n",
    "#### List\n",
    "We use list in the Solver class to track how many independent variables have been created so far and store copies of these independent variables. \n",
    "\n",
    "#### Numpy array\n",
    "In Variable class, a numpy array with length equal to the number of independent variables (provided by the user when the Solver class object is first created) is used to store the derivative information. \n",
    "\n",
    "### Core classes and important attributes\n",
    "There are two core classes in the veritorch package: the solver class and the variable class\n",
    "\n",
    "#### Solver class\n",
    "\n",
    "This class takes as an input the number of independent variables that the function $f$ has and tracks how many independent variables we have already created so far. \n",
    "\n",
    "It has the following attributes:\n",
    "* n: the number of independent variables the function $f$ has\n",
    "* independent_variable_list: a list of independent variables that we have created so far using this solver class\n",
    "\n",
    "We plan to implement the following methods for this solver class:\n",
    "* create_variable(x): return an independent variable with value initialized to x and derivative dx initialized to a numpy array of zeros of shape n. If this is the $i^{th}$ time we call the create_variable(x) method of this solver class, then we will set dx[i] to be 1 before we ruturn the created variable. A copy of this created independent variable will also be added to the independent_variable_list.\n",
    "* get_variable(idx): return the copy of the $i^{th}$ independent variable stored in the independent_variable_list. If the user accidentally overwrites the independent variables he/she created before, this method can be called to retrieve a copy of that independent variable so that the user do not need to start the whole process again.\n",
    "* merge(*args): *args should be a list of variables $[f_1, f_2, ..., f_m]$. This function returns the m by n jacobian matrix of $f=[f_1, f_2, ..., f_m]$. \n",
    "\n",
    "#### Variable class\n",
    "This class takes as inputs the initial value $x$ and derivative $dx$ (optional, set to None by default) and includes methods to overload basic arithmic operators for the veritorch package.\n",
    "\n",
    "It has the following attributes:\n",
    "* x: the current scalar value of this variable\n",
    "* dx: the current derivative of this variable, which should be a vector of length n, where n is the number of independent variables of the function $f$ whose derivative is being evaluated. Note that since the derivative vectors of variables created by the same Solver class and variables that are arithmetic products of those variables created by the same Solver class always have the same length/shape, we no longer need to figure out a way to determine whether two variable objects are independent or not.\n",
    "\n",
    "We have implemented in this milestone the following methods for this variable class:\n",
    "* \\_\\_str\\_\\_\n",
    "* \\_\\_neg\\_\\_\n",
    "* \\_\\_add\\_\\_\n",
    "* \\_\\_radd\\_\\_\n",
    "* \\_\\_sub\\_\\_\n",
    "* \\_\\_rsub\\_\\_\n",
    "* \\_\\_mul\\_\\_\n",
    "* \\_\\_rmul\\_\\_\n",
    "* \\_\\_truediv\\_\\_\n",
    "* \\_\\_rtruediv\\_\\_\n",
    "* \\_\\_pow\\_\\_\n",
    "\n",
    "The methods above take as input two variable class objects and return a new variable class object with its value and derivative updated according to the arithmetic rule it corresponds to using the chain rule.\n",
    "\n",
    "### Elementary functions\n",
    "To support the usage of elementary functions in our library, we have implemented the following methods for our variable class:\n",
    "* exp(x)\n",
    "* log(x)\n",
    "* sin(x)\n",
    "* cos(x)\n",
    "* tan(x)\n",
    "* arcsin(x)\n",
    "* arccos(x)\n",
    "* arctan(x)\n",
    "\n",
    "The methods above take as input a variable class object and return a new variable class object with its value and derivative updated according to the elementary function it corresponds to using the chain rule. \n",
    "\n",
    "### Aspects not implemented yet\n",
    "#### Vector-valued functions\n",
    "The implementation we have now only handles the scalar-output functions, $\\mathbb{R}^n \\rightarrow \\mathbb{R}^1$. We will make it more general by finishing the implemention of the merge method outlined in the Solver class above. This will allow us to handle functions $f: \\mathbb{R}^n \\rightarrow \\mathbb{R}^m$. \n",
    "\n",
    "### External dependencies\n",
    "1. NumPy: it provides us an efficient way to compute the intermediate multidimentional results and organize value and derivative vectors.\n",
    "\n",
    "2. pytest: it provides us a systematic way to test every line of code written in the veritorch library\n",
    "\n",
    "3. setuptools: it is used to package our repo before we distribute it.\n",
    "\n",
    "4. TravisCI and Codecov: they are our test suites. \n",
    "\n",
    "## Future Features\n",
    "### Optimization methods\n",
    "There are plenty of unconstrained optimization methods that require the derivative information of a function. We plan to implement some of them: Newton's Method, Broyden–Fletcher–Goldfarb–Shanno (BFGS) method, conjugate gradient (CG) method, etc.\n",
    "\n",
    "As we implement these methods, we will see whether our implementation can give us the required derivative information fast enough and whether the returned results are user friendly or not, and change our implementation accordingly. \n",
    "\n",
    "### Vectorized processing\n",
    "If our user wants to compute a vector-valued function $f: R^n \\rightarrow R^m$, our current design of veritorch requires the user to express $f_i$ in terms of the created variables for all $1\\leq i\\leq m$. However, there are cases where the vector-valued function $f$ consists of only elementwise operations. For example, $f(x)=2*sin(x), x\\in R^n$. In such case, the user will have to input the same expression many times for each $1\\leq i\\leq n$. Therefore, it might be beneficial to support a special \"vectorized processing\" mode to reduce the workload of users if they are evaluating derivatives of some functions that involve elementwise operations only.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
