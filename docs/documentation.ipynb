{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>CS 207 Final Project: Documentation</center>\n",
    "<center>December 2019</center>\n",
    "\n",
    "## Introduction\n",
    "\n",
    "\n",
    "Efficiently and accurately evaluating derivatives of functions is one of the most important operations in science and engineering. Automatic differentiation (AD) is a technique which, given a function $f$ and a point, automatically evaluates that point's derivative. AD is less costly than symbolic defferentiation, while achieving machine precision compared with finite differentiation. This library implements both forward mode and reverse mode of AD. A user can simply input a function $f$ and a vector $\\mathbf{x}$, specify the mode that they want, and then they will be able to get the value and derivative computed by the specified mode right away.\n",
    "\n",
    "\n",
    "## Background\n",
    "\n",
    "We present below some of the key concepts and formulae upon which we build the veritorch library:\n",
    "\n",
    "### Chain rule\n",
    "\n",
    "Chain rule is fundamental to AD when we decompose functions.\n",
    "\n",
    "Suppose we have $h(u(t), v(t))$, its derivative with respect to $t$ is:\n",
    "\n",
    "$$\\frac{\\partial h}{\\partial t} = \\frac{\\partial h}{\\partial u}\\frac{\\partial u}{\\partial t} + \\frac{\\partial h}{\\partial v}\\frac{\\partial v}{\\partial t}.$$\n",
    "\n",
    "For the general function $h(y_1(\\mathbf{x}), \\dotsc,y_n(\\mathbf{x}))$, where we replace $t$ with a vector $\\mathbf{x} \\in \\mathbb{R}^m$ and $h$ a function of $n$ other functions $y_i$, the derivative is:\n",
    "\n",
    "$$\\nabla_x h = \\sum_{i=1}^n \\frac{\\partial h}{\\partial y_i} \\nabla y_i(\\mathbf{x})$$\n",
    "\n",
    "### Jacobians and vectors\n",
    "\n",
    "If we have a function $\\mathbf{y}(\\mathbf{x})$: $\\mathbb{R}^n \\rightarrow \\mathbb{R}^m$, the Jacobian matrix of it is a matrix representing all the possible partial derivatives combinations as follows:\n",
    "$$\n",
    "\\mathbf{J} = \\begin{bmatrix}\n",
    "\\frac{\\partial \\mathbf{y}}{\\partial x_1} & \\dots  & \\frac{\\partial \\mathbf{y}}{\\partial x_n}\n",
    "\\end{bmatrix} = \\begin{bmatrix} \n",
    "\\frac{\\partial {y_1}}{\\partial x_1} & \\dots & \\frac{\\partial {y_1}}{\\partial x_n} \\\\\n",
    "\\vdots & \\ddots & \\vdots\\\\\n",
    "\\frac{\\partial {y_m}}{\\partial x_1} & \\dots & \\frac{\\partial {y_m}}{\\partial x_n} \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "In general, for example, we have a function $g(\\mathbf{y}(\\mathbf{x}))$. Suppose a vector $\\mathbf{v}$ happens to be the gradient of g with respect the vector $\\mathbf{y}$ as follows: \n",
    "$$\n",
    "\\mathbf{v} = \\begin{bmatrix}\n",
    "\\frac{\\partial g}{\\partial y_1} & \\dots & \\frac{\\partial g}{\\partial y_m}\n",
    "\\end{bmatrix} ^T\n",
    "$$\n",
    "To get the gradient of g with respect to $\\mathbf{x}$, we multiply Jacobian matrix $\\mathbf{J}$ with vector $\\mathbf{v}$: \n",
    "\n",
    "$$\\mathbf{J} \\cdot \\mathbf{v} = \\begin{bmatrix} \n",
    "\\frac{\\partial {y_1}}{\\partial x_1} & \\dots & \\frac{\\partial {y_m}}{\\partial x_n} \\\\\n",
    "\\vdots & \\ddots & \\vdots\\\\\n",
    "\\frac{\\partial {y_1}}{\\partial x_1} & \\dots & \\frac{\\partial {y_m}}{\\partial x_n} \\\\\n",
    "\\end{bmatrix} \n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial g}{\\partial y_1} \\\\\n",
    "\\vdots \\\\ \n",
    "\\frac{\\partial g}{\\partial y_m}\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "\\frac{\\partial g}{\\partial x_1} \\\\\n",
    "\\vdots \\\\ \n",
    "\\frac{\\partial g}{\\partial x_n}\n",
    "\\end{bmatrix} $$\n",
    "\n",
    "### Computational graphs \n",
    "\n",
    "AD exploits the idea that complicated equations could be converted into a sequence of elementary operations which have specified routines for computing derivatives. This process, also called the evaluation trace, can be visualized by a computational graph where each step is an elementary operation. For example, we want to evaluate the derivative of the function: $$f(x) = 5\\exp(x^2)+\\sin(3x)$$\n",
    "Here in this example, the right-most $x_7$ represents the value of $f(x)$, while the left-most $x$ represents our input variable. We construct a computational graph where we take the input $x$ as a node, and we take the constants as nodes as well when applicable. These nodes are connected by lines (edges) to represent the flow of information. \n",
    "![](https://i.imgur.com/uBUpnfc.jpg=300x)\n",
    "\n",
    "\n",
    "\n",
    "### Elementary functions\n",
    "\n",
    "Elementary Functions | Example | Derivative\n",
    ":-:|:-:|:-:\n",
    "exponentials| $e^x$ | $e^x$   \n",
    "logarithms|$log(x)$| $\\frac{1}{x}$ \n",
    "powers| $x^2$| $2x$ \n",
    "trigonometrics| $sin(x)$ | $cos(x)$ \n",
    "inverse trigonometrics|  $arcsin(x)$ | $\\frac{1}{\\sqrt{(1-x^2)}}$ \n",
    "\n",
    "\n",
    "### Dual number\n",
    "$\\forall z_1=x_1+y_1\\epsilon, z_2=x_2+y_2\\epsilon,$ where $x_1, y_1, x_2, y_2\\in \\mathbb{R}$, we have the following properties for dual number:\n",
    "1. $z_1+z_2=(x_1+x_2)+(y_1+y_2)\\epsilon$\n",
    "2. $z_1z_2=(x_1x_2)+(x_1y_2+x_2y_1)\\epsilon$\n",
    "3. $z_1/z_2=(\\frac{x_1}{x_2})+\\frac{x_2y_1-x_1y_2}{x_2^2}$\n",
    "\n",
    "As can be seen from the equations above, there is a close connection between the multiplication/division of dual numbers and the product/quotient rules for derivatives:\n",
    "$$(f(x)g(x))'=f'(x)g(x)+f(x)g'(x)$$\n",
    "$$(\\frac{f(x)}{g(x)})'=\\frac{f'(x)g(x)-f(x)g'(x)}{g^{2}(x)}$$.\n",
    "\n",
    "### Forward mode\n",
    "Our veritorch package supports forward mode, which uses chain rule to propogate the gradient with respect to the input/independent variables along the computational graph. In the process of gradient propogation, we use the class named Variable that can be updated in a fashion similar to the dual number formula listed above to store the intermediate values and derivatives. In the end, our package will return the jacobian vector product $Jp$. As a result, the forward mode depends on the number of independent parameters involved in the function $f$. If a function actually involves many independent parameters, the forward mode might not be efficient enough and the reverse mode should be considered instead. However, due to time constraint, we might not be able to add support of reverse mode to our veritorch package.\n",
    "\n",
    "### Reverse mode\n",
    "Our veritorch package also supports reverse mode, which is still based on the chain rule, but we traverse the chain rule from outside to inside, or, in terms of the computational graph, from right to left. For example, if we have a final node $z$ and input nodes $t_i$, and the path from $z$ to $t_i$ goes through intermediate nodes $x_{p}$, that is, $z = g(x_{p}) = g(f(t_i))$, then we have the drivative:\n",
    "\n",
    "$$\\frac{\\partial z}{\\partial t_i} = \\sum_{p\\in parents(i)} \\frac{\\partial z}{\\partial x_p} \\frac{\\partial x_p}{\\partial t_i}$$\n",
    "\n",
    "That is to say, we only need to know the derivatives of its parents and the formula, in order to calculate the derivative of the output $z$ with respect to input variable $t_i$. More specifically, let's continue to take the example of the function $f(x) = 5\\exp(x^2)+\\sin(3x)$. The reverse mode starts from the end, where we have a \"seed\":\n",
    "$$\\frac{\\partial f}{\\partial x_7} = 1$$\n",
    "\n",
    "Since we have $x_7 = x_4 + x_6$ and use chain rule, we get:\n",
    "\n",
    "$$\\frac{\\partial f}{\\partial x_6} = \\frac{\\partial f}{\\partial x_7} \\frac{\\partial x_7}{\\partial x_6} = \\frac{\\partial f}{\\partial x_7}\\cdot1 = 1$$\n",
    "\n",
    "Similarly, given $x_6 = sin(x_5)$, we can easily obtain: \n",
    "\n",
    "$$\\frac{\\partial f}{\\partial x_5} = \\frac{\\partial f}{\\partial x_6} \\frac{\\partial x_6}{\\partial x_5} = 1\\cdot cosx_5 = cos(3)$$\n",
    "\n",
    "We do the same thing to all nodes in the computational graph as listed below, and $\\frac{\\partial f}{\\partial x_1}$ is the final answer that we want, as $x_1$ is our input variable. \n",
    "\n",
    "$$\\frac{\\partial f}{\\partial x_4} = \\frac{\\partial f}{\\partial x_7} \\frac{\\partial x_7}{\\partial x_4} = 1\\cdot 1 = 1$$\n",
    "\n",
    "$$\\frac{\\partial f}{\\partial x_3} = \\frac{\\partial f}{\\partial x_4} \\frac{\\partial x_4}{\\partial x_3} = 1\\cdot 5 = 5$$\n",
    "\n",
    "$$\\frac{\\partial f}{\\partial x_2} = \\frac{\\partial f}{\\partial x_3} \\frac{\\partial x_3}{\\partial x_2} = 5\\cdot exp(x_2^2) = 5e$$\n",
    "\n",
    "$$\\frac{\\partial f}{\\partial x_1} = \\frac{\\partial f}{\\partial x_2} \\frac{\\partial x_2}{\\partial x_1} + \\frac{\\partial f}{\\partial x_5} \\frac{\\partial x_5}{\\partial x_1}= 5exp(x_2^2)\\cdot 2x_1 + cosx_5\\cdot3 = 10e + 3cos(3)$$\n",
    "\n",
    "The table below lists all the basic functions and values that we need for the calculation.\n",
    "\n",
    "Trace | Elementary Functions | Current Function Value| Derivative wrt 1st Element | Derivative Value wrt 1st Element|  Derivative wrt 2nd Element| Derivative Value wrt 2nd Element\n",
    ":-:|:-:|:-:|:-:|:-:|:-:|:-:\n",
    "$x_1$| $x$ | $1$  | $1$| $1$| $1$| $1$  \n",
    "$x_2$| $x_1^2$ | $1$  | $2x_1$| $2$| $-$| $-$\n",
    "$x_3$| $exp(x_2)$ | $e$  | $exp(x_2)$| $e$| $-$| $-$\n",
    "$x_4$| $5x_3$ | $5e$  | $5$| $5$| $-$| $-$\n",
    "$x_5$| $3x_1$ | $3$  | $3$| $3$| $-$| $-$\n",
    "$x_6$| $sin(x_5)$ | $sin(3)$  | $cos(x_5)$| $cos(3)$| $-$| $-$\n",
    "$x_7$| $x_4+x_6$ | $5e+sin(3)$  | $1$| $1$| $1$| $1$\n",
    "\n",
    "## How to use veritorch\n",
    "\n",
    "To use the veritorch package, users should first run the commands provided below to install our package via pip and import it. We have already uploaded our veritorch package to PyPI.\n",
    "\n",
    "```\n",
    "pip install veritorch\n",
    "python\n",
    ">>>import veritorch.veritorch as vt\n",
    "```\n",
    "\n",
    "After successfully installing and importing the veritorch package, users can take the following steps to evaluate the derivative of $f$ at a point $x$. Here we take the most complicated case of all: a vector to vector function, as an example: $$\\textbf{f(z)} = [f_1(x,y), f_2(x,y)]=[x*y, x*y + 2*x + 2*y]$$ evaluated at $$\\textbf{z}=(x,y)=(1,2).$$ \n",
    "\n",
    "```\n",
    "# First, create an instance of Solver class in the veritorch package\n",
    "# that tracks how many of independent variables $f$ takes as input.\n",
    "\n",
    ">>>sol=vt.Solver(2)\n",
    "\n",
    "# Second, define the function:\n",
    "# (regardless of type of function, MUST RETURN A LIST)\n",
    "\n",
    ">>>def f(x,y):\n",
    "...    return [x*y, x*y + 2*x + 2*y]\n",
    "\n",
    "# Last, pass in the function and point of evaluation to sol to get the Jacobian:\n",
    "\n",
    ">>>dx=sol.get_diff(f,[1,2])\n",
    ">>>print(dx)\n",
    "np.array([[2,1], [4,3]])\n",
    "\n",
    "# the default mode is forward mode as above, but user can specify \"backward\" for parameter mode in get_diff method to use reverse mode:\n",
    "\n",
    ">>>dx=sol.get_diff(f,[1,2], mode = \"backward\")\n",
    ">>>print(dx)\n",
    "np.array([[2,1], [4,3]])\n",
    "\n",
    "# if the user would like to get function value IN ADDITION \n",
    "# to the derivative at the evaluation point, they can call \n",
    "# evaluate_and_get_diff method instead, again with both modes implemented:\n",
    "# (if it's a scalar function, val will return a scalar)\n",
    "# (if it's a vector function, val will return a list)\n",
    "\n",
    ">>>val, dx=sol.evaluate_and_get_diff(f,[1,2], \"backward\")\n",
    ">>>print(val)\n",
    "[2,8]\n",
    ">>>print(dx)\n",
    "np.array([[2,1], [4,3]])\n",
    "```\n",
    "\n",
    "For advanced users, the veritorch package also supports limited, but sometimes more flexible \"under-the-hood\" usages. Examples below.\n",
    "\n",
    "Inputting composite functions that involve operations on elementary and common functions, including but not limited to $sin(x), cosh(x), exp(x), arcsin(x), logistic(x)$:\n",
    "\n",
    "\n",
    "1. Using forward mode:\n",
    "\n",
    "\n",
    "```\n",
    "# Example 1: using operation overload:\n",
    "\n",
    "# First, create an instance of solver class in the veritorch package that\n",
    "# tracks how many of independent variables $f$ takes as input.\n",
    "\n",
    ">>>sol=vt.Solver(3)\n",
    "\n",
    "# Next, use the method create_variable(initial_value) of solver class\n",
    "# to create variable x1, x2, x3 with their values initialized to 4, 5, 6 \n",
    "# (and partial derivatives, with respect to x1, x2, x3 respectively \n",
    "# initialized to 1 by default)\n",
    "\n",
    ">>>x1=sol.create_variable(4)\n",
    ">>>x2=sol.create_variable(5)\n",
    ">>>x3=sol.create_variable(6)\n",
    ">>>f1=x1*x2*x3\n",
    ">>>print(f1)\n",
    "Variable(120, [30,24,20])\n",
    "\n",
    "# It outpus (function value, gradient) at the point of evaluation.\n",
    "```\n",
    "\n",
    "```\n",
    "# Example 2: Using functions implemented in Numpy (can directly use np.function method):\n",
    "\n",
    ">>>import math\n",
    ">>>import numpy as np\n",
    ">>>sol=vt.Solver(1)\n",
    ">>>x1=sol.create_variable(math.pi)\n",
    ">>>f1=np.sin(x1)\n",
    ">>>f2=np.cos(f1)\n",
    ">>>f3=np.exp(f2)\n",
    ">>>print(f3)\n",
    "Variable(2.718281828459045, [3.32893514e-16])\n",
    "```\n",
    "```\n",
    "# Example 3: Using functions not implemented in Numpy (cannot use np.function methods):\n",
    "\n",
    ">>>import numpy as np\n",
    ">>>sol=vt.Solver(1)\n",
    ">>>x1=sol.create_variable(3)\n",
    ">>>f1=x1.logistic()\n",
    ">>>print(f1)\n",
    "Variable(0.9525741268224334, [0.04517666])\n",
    "```\n",
    "\n",
    "\n",
    "2. Using reverse mode:\n",
    "\n",
    "\n",
    "```\n",
    "# Example 1: using operation overload:\n",
    "\n",
    "# First, create an instance of solver class in the veritorch package that\n",
    "# tracks how many of independent variables $f$ takes as input.\n",
    "\n",
    ">>>sol=vt.Solver(3)\n",
    "\n",
    "# Next, use the method create_variable_b(initial_value) of solver class\n",
    "# to create variable x1, x2, x3 with their values initialized to 4, 5, 6\n",
    "\n",
    ">>>x1=sol.create_variable_b(4)\n",
    ">>>x2=sol.create_variable_b(5)\n",
    ">>>x3=sol.create_variable_b(6)\n",
    ">>>f1=x1*x2*x3\n",
    ">>>f1.grad_value=1\n",
    ">>>dx1=x1.grad()\n",
    ">>>dx2=x2.grad()\n",
    ">>>dx3=x3.grad()\n",
    "\n",
    "#dx1 is now df1/dx1\n",
    ">>>print(dx1)\n",
    "30\n",
    "\n",
    "#dx2 is now df1/dx2\n",
    ">>>print(dx2)\n",
    "24\n",
    "\n",
    "#dx3 is now df1/dx3\n",
    ">>>print(dx3)\n",
    "20\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "# Example 2: Using functions implemented in Numpy (can directly use np.function method):\n",
    "\n",
    ">>>import math\n",
    ">>>import numpy as np\n",
    ">>>sol=vt.Solver(1)\n",
    ">>>x1=sol.create_variable_b(math.pi)\n",
    ">>>f1=np.sin(x1)\n",
    ">>>f2=np.cos(f1)\n",
    ">>>f3=np.exp(f2)\n",
    ">>>f3.grad_value=1\n",
    ">>>dx1=x1.grad()\n",
    ">>>print(dx1)\n",
    "3.328935140402784e-16\n",
    "```\n",
    "\n",
    "```\n",
    "# Example 3: Using functions not implemented in Numpy (cannot use np.function methods):\n",
    "\n",
    ">>>import numpy as np\n",
    ">>>sol=vt.Solver(1)\n",
    ">>>x1=sol.create_variable_b(3)\n",
    ">>>f1=x1.logistic()\n",
    ">>>f1.grad_value=1\n",
    ">>>dx1=x1.grad()\n",
    ">>>print(dx1)\n",
    "0.04517665973091213\n",
    "```\n",
    "\n",
    "\n",
    "## Software organization\n",
    "\n",
    "### Directory structure\n",
    "\n",
    "The final repo follow the directory structure below:\n",
    "```\n",
    "cs207-FinalProject/\n",
    "    README.md\n",
    "    requirements.txt\n",
    "    LICENSE\n",
    "    setup.py\n",
    "    veritorch/\n",
    "        __init__.py\n",
    "        veritorch.py\n",
    "        ...\n",
    "    test/\n",
    "        test.py\n",
    "        ...\n",
    "    docs/\n",
    "        milestone1.ipynb\n",
    "        milestone2.ipynb\n",
    "        documentation.ipynb\n",
    "        ...\n",
    "```\n",
    "\n",
    "### Modules\n",
    "We choose to have only one module published: the veritorch module within our veritorch package. The veritorch module includes a Solver class, a Variable class and a Variable_b class:\n",
    "* The Solver class, once initialized with a number $n$, can provide methods to evaluate the value and derivative of many elementary functions that has exactly n independent variable inputs. Both forward mode and reverse mode are supported. The Solver class will use the Variable class to do the forward mode and the Variable_b class to do the backward mode.\n",
    "* The Variable class takes as input the initial value $x$, and includes methods to overload basic arithmic operators to support forward mode for the veritorch package. \n",
    "* The Variable_b class takes as input the initial value $x$, and includes methods to overload basic arithmic operators to support reverse mode for the veritorch package.\n",
    "\n",
    "### Testing\n",
    "All files related to testing will be put in the directory cs207-FinalProject/test/. We use TravisCI to check whether each pull request can actually build and Codecov to check how many lines of code have been tested. We have activated both of them for this repo and included the badges in the README.md file at the root directory.\n",
    "\n",
    "### Distrubution of the package\n",
    "We use twine to upload the veritorch package to PyPI (Python Packaging Index) for package distribution. This allows users to search and download packages by keywords using pip and pipenv. We have already done so and the latest version can be viewed here: https://pypi.org/project/veritorch/0.1.0/\n",
    "\n",
    "## Implementation\n",
    "\n",
    "### Core data structures\n",
    "#### List\n",
    "* We use list in the Solver class to track how many independent variables have been created so far and store copies of these independent variables.\n",
    "* We use list in the Variable_b class to dynamically track the descendants of this variable in the computational graph for reverse mode.\n",
    "\n",
    "#### Numpy array\n",
    "In Variable class, a numpy array with length equal to the number of independent variables (provided by the user when the Solver class object is first created) is used to store the derivative information. \n",
    "\n",
    "### Core classes and important attributes\n",
    "There are three core classes in the veritorch package: the solver class, the variable class and the variable_b class\n",
    "\n",
    "#### Solver class\n",
    "\n",
    "The Solver class, as indicated above, once initialized with a number $n$, can evaluate the value and derivative of many elementary functions that has exactly n independent variable inputs using the methods presented in the following paragraphs. \n",
    "\n",
    "It has the following attributes:\n",
    "* n: the number of independent variables the target function $f$ has\n",
    "* independent_variable_list: a list of independent variables that we have created so far using this solver class\n",
    "\n",
    "The following methods form the core of this Solver class:\n",
    "* create_variable(x): return an object of the Variable class with value initialized to x and derivative dx initialized to a numpy array of zeros of shape n. If this is the $i^{th}$ time we call the create_variable(x) method of this solver class, then we will set dx[i] to be 1 before we ruturn the created variable. A copy of this created independent variable will also be added to the independent_variable_list.\n",
    "\n",
    "* create_variable_b(x): return an object of the Variable_b class with value initialized to x and derivative dx initialized to None. A copy of this created independent variable will also be added to the independent_variable_list.\n",
    "\n",
    "* get_variable(idx): return the copy of the $i^{th}$ independent variable stored in the independent_variable_list. If the user accidentally overwrites the independent variables he/she created before, this method can be called to retrieve a copy of that independent variable so that the user do not need to start the whole process again. However, we recommend the usage of this method for forward mode only, because we choose to dynamically track variables for reverse mode and accidental overwrite is possible to impact this dynamic tracking process.\n",
    "\n",
    "* merge(d_list): d_list should be a list of derivatives $[df_1, df_2, ..., df_m]$. This method returns the m by n jacobian matrix of $f=[f_1, f_2, ..., f_m]$.\n",
    "\n",
    "* evaluate_and_get_diff_forward(f, x): This method returns the value and derivative of f evaluated at x computed using the forward mode. Please note that f **must** be defined to return a list, regardless of the type of function.\n",
    "\n",
    "* evaluate_and_get_diff_backward(f, x): This method returns the value and derivative of f evaluated at x computed using the backward mode. Please note that f **must** be defined to return a list, regardless of the type of function.\n",
    "\n",
    "* get_diff(f, x, mode=\"forward\"): This method returns the derivative of f evaluated at x computed using the mode specified by user, which is set to be the forward mode by default. Please note that f **must** be defined to return a list, regardless of the type of function. \n",
    "\n",
    "* evaluate_and_get_diff(f, x, mode=\"forward\"): This method returns the value and derivative of f evaluated at x computed using the mode specified by user, which is set to be the forward mode by default. Please note that f **must** be defined to return a list, regardless of the type of function.\n",
    "\n",
    "#### Variable class\n",
    "This class takes as inputs the initial value $x$ and derivative $dx$ (optional, set to None by default) and includes methods to overload basic arithmic operators to support the forward mode for the veritorch package.\n",
    "\n",
    "It has the following attributes:\n",
    "* x: the current scalar value of this variable\n",
    "* dx: the current derivative of this variable, which should be a vector of length n, where n is the number of independent variables of the function $f$ whose derivative is being evaluated. Note that since the derivative vectors of variables created by the same Solver class and variables that are arithmetic products of those variables created by the same Solver class always have the same length/shape, we no longer need to figure out a way to determine whether two variable objects are independent or not.\n",
    "\n",
    "We have implemented in this milestone the following methods for this variable class:\n",
    "* \\_\\_str\\_\\_\n",
    "* \\_\\_neg\\_\\_\n",
    "* \\_\\_add\\_\\_\n",
    "* \\_\\_radd\\_\\_\n",
    "* \\_\\_sub\\_\\_\n",
    "* \\_\\_rsub\\_\\_\n",
    "* \\_\\_mul\\_\\_\n",
    "* \\_\\_rmul\\_\\_\n",
    "* \\_\\_truediv\\_\\_\n",
    "* \\_\\_rtruediv\\_\\_\n",
    "* \\_\\_pow\\_\\_\n",
    "* \\_\\_eq\\_\\_\n",
    "* \\_\\_ne\\_\\_\n",
    "\n",
    "The methods above(excluding the str, eq and ne methods) take as input two variable class objects and return a new variable class object with its value and derivative updated according to the arithmetic rule it corresponds to using the chain rule.\n",
    "\n",
    "#### Variable_b class\n",
    "This class takes as inputs the initial value $x$ and includes methods to overload basic arithmic operators to support the reverse mode for the veritorch package.\n",
    "\n",
    "It has the following attributes:\n",
    "* value: the current scalar value of this variable\n",
    "* children: a list, tracking the descendants of this variable in the computational graph and the associated weights fully determined by the chain rule\n",
    "* grad_value: the current derivative of this variable. It is initialized to None when an object of class Variable_b is created and will remain to be None until the grad() method(presented below) of this node or its ancestors is called. Then grad_value will be updated according to some update rules presented below.\n",
    "\n",
    "The following method forms the core of this Variable_b class:\n",
    "* grad(): A recursive method. If the grad_value attribute is not None, this method will simply return the value of grad_value attribute. Otherwise, it will be updated as a weighted sum of the result of the grad() method called on its descendants(stored in the children list), where the weight is fully determined by the chain rule. Please note that since we update the value of grad_value attribute after we finish computing this weighted sum, we will not need to compute the derivative of this variable and its descendants any more if some ancestors of this variable call grad() in the future.\n",
    "\n",
    "We have implemented the following methods for this Variable_b class:\n",
    "* \\_\\_str\\_\\_\n",
    "* \\_\\_neg\\_\\_\n",
    "* \\_\\_add\\_\\_\n",
    "* \\_\\_radd\\_\\_\n",
    "* \\_\\_sub\\_\\_\n",
    "* \\_\\_rsub\\_\\_\n",
    "* \\_\\_mul\\_\\_\n",
    "* \\_\\_rmul\\_\\_\n",
    "* \\_\\_truediv\\_\\_\n",
    "* \\_\\_rtruediv\\_\\_\n",
    "* \\_\\_pow\\_\\_\n",
    "* \\_\\_eq\\_\\_\n",
    "* \\_\\_ne\\_\\_\n",
    "\n",
    "The methods above(excluding the str, eq and ne methods) take as input two Variable_b class objects, create a new Variable_b class object with its value and derivative initialized according to the corresponding operation, add the computed weight and this newly created object as a tuple to the children attribute of two input Variable_b class objects and return the newly created object.\n",
    "\n",
    "### Elementary and common functions\n",
    "To support the usage of elementary and common functions in our library, we have implemented the following methods for our variable class:\n",
    "* exp(x)\n",
    "* log(x)\n",
    "* sin(x)\n",
    "* cos(x)\n",
    "* tan(x)\n",
    "* arcsin(x)\n",
    "* arccos(x)\n",
    "* arctan(x)\n",
    "* exponential(x, a)\n",
    "* sinh(x)\n",
    "* cosh(x)\n",
    "* tanh(x)\n",
    "* logistic(x)\n",
    "* logarithm(x, a)\n",
    "* sqrt(x)\n",
    "\n",
    "For the forward mode, the methods above take as input a variable class object and return a new variable class object with its value and derivative updated according to the elementary function it corresponds to using the chain rule. \n",
    "\n",
    "For the reverse mode, The methods above take as input two Variable_b class objects, create a new Variable_b class object with its value and derivative initialized according to the corresponding operation, add the computed weight and this newly created object as a tuple to the children attribute of two input Variable_b class objects and return the newly created object.\n",
    "\n",
    "Special Note:\n",
    "Usage of the following functions requires some special handling:\n",
    "* exponential(x, a)\n",
    "* sinh(x)\n",
    "* cosh(x)\n",
    "* tanh(x)\n",
    "* logistic(x)\n",
    "* logarithm(x, a)\n",
    "* sqrt(x)\n",
    "\n",
    "When we want to define a function, for example, $f(x,y)=($sqrt$($logistic$(x))$, cosh$(y))$ that involves the usage of functions listed above, in order to use the veritorch package, we have to define it in python as follows:\n",
    "```\n",
    "define f(x,y):\n",
    "    return [(x.logistic()).sqrt(), y.cosh()]\n",
    "```\n",
    "Then user can use the evaluate_and_get_diff(f, x, mode=\"forward\") method of the Solver class to get the value and derivative of $f$ evaluated at some point $(x_0,y_0)$.\n",
    "\n",
    "### External dependencies\n",
    "1. NumPy: it provides us an efficient way to compute the intermediate multidimentional results and organize value and derivative vectors.\n",
    "\n",
    "2. pytest: it provides us a systematic way to test every line of code written in the veritorch library\n",
    "\n",
    "3. setuptools: it is used to package our repo before we distribute it.\n",
    "\n",
    "4. TravisCI and Codecov: they are our test suites. \n",
    "\n",
    "## Our extension\n",
    "We have implemented the reverse mode as our additional feature. The reverse mode supports the same functionality supported by the forward mode. In addition, we have added two methods in the Solver class: \n",
    "* get_diff(f, x, mode=\"forward\")\n",
    "* evaluate_and_get_diff(f, x, mode=\"forward\")\n",
    "\n",
    "so users can get any function $f$ and its derivative evaluated at some point more conveniently. We have incorporated the relevant mathematical concepts as well as implementation details in Background and Implementation Details sections.  \n",
    "\n",
    "## Future\n",
    "### Optimization methods\n",
    "There are plenty of unconstrained optimization methods that require the derivative information of a function. These optimization methods can be useful for many area of Science. In the future we could implement some of them: Newton's Method, Broyden–Fletcher–Goldfarb–Shanno (BFGS) method, conjugate gradient (CG) method, etc.\n",
    "\n",
    "As we implement these methods, we will see whether our implementation can give us the required derivative information fast enough and whether the returned results are user friendly or not, and change our implementation accordingly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
